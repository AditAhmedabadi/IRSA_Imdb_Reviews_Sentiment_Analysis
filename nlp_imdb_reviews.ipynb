{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_imdb_reviews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anHe8KleuzQV"
      },
      "source": [
        "## Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byt6dQK5mjy3",
        "outputId": "97381b47-8585-4909-e2f2-ad34bdcc647c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3qQxFd0u2FO"
      },
      "source": [
        "### Downloading Dataset form tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPycC4r7qlyY"
      },
      "source": [
        "imdb , info = tfds.load('imdb_reviews' , as_supervised = True , with_info = True)\n",
        "\n",
        "train_data , test_data = imdb['train'] , imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7OF41IbsObt"
      },
      "source": [
        "## Extracting Train and Test Sentences and their corresponding Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERqMANSIwAfU"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "for sentence,label in train_data:\n",
        "  training_sentences.append(sentence.numpy().decode('utf8'))\n",
        "  training_labels.append(label.numpy())\n",
        "  \n",
        "for sentence,label in test_data:\n",
        "  testing_sentences.append(sentence.numpy().decode('utf8'))\n",
        "  testing_labels.append(label.numpy())\n",
        "  \n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqdHTx3isW9W"
      },
      "source": [
        "## Initializing Tokenizer and converting sentences into padded sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMs3v-11y_hD"
      },
      "source": [
        "vocab_size = 20000\n",
        "embed_dims = 16\n",
        "truncate = 'post'\n",
        "pad = 'post'\n",
        "oov_token = '<OOV>'\n",
        "max_length = 150\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size , oov_token = oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_train = pad_sequences(train_sequences , truncating = truncate , padding = pad , maxlen = max_length)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "padded_test = pad_sequences(test_sequences , truncating=truncate , padding = pad , maxlen = max_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rwhz2KWtHg1"
      },
      "source": [
        "## Decoding Sequences back into Texts by creating a reverse word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL7Yi0DH0F6I",
        "outputId": "89ee028e-560d-412a-e2c2-a015db4d1186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "reverse_word_index = dict([(values , keys) for keys , values in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i , '?') for i in text])\n",
        "\n",
        "print(decode_review(padded_train[3]))\n",
        "print(training_sentences[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is the kind of film for a snowy sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm chair and mellow for a couple of hours wonderful performances from cher and nicolas cage as always gently row the plot along there are no <OOV> to cross no dangerous waters just a warm and witty <OOV> through new york life at its best a family film in every sense and one that deserves the praise it received ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIxlRg64tRGO"
      },
      "source": [
        "### Making DNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18EUUuF1cGs"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size , embed_dims , input_length= max_length),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(units = 6 , activation = 'relu'),\n",
        "                             tf.keras.layers.Dense(units = 1 , activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o373EBNtVHA"
      },
      "source": [
        "### Summary of the Model's Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt3Q8DDG4zIs",
        "outputId": "ca5a5012-9113-49d2-a0e7-42c28fecd402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 150, 16)           320000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 14406     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 334,413\n",
            "Trainable params: 334,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bffilsJ7tYav"
      },
      "source": [
        "### Initialzing a callback to avoid overfitting , Fitting the data on the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWIVGJnE42ZW",
        "outputId": "0e622b19-3132-41e2-ee63-65e10c552909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "\n",
        "model.fit(\n",
        "    padded_train,\n",
        "    training_labels_final,\n",
        "    epochs = 10,\n",
        "    validation_data = (padded_test , testing_labels_final),\n",
        "    callbacks = [callbacks]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4824 - accuracy: 0.7440 - val_loss: 0.3633 - val_accuracy: 0.8377\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1942 - accuracy: 0.9288 - val_loss: 0.4113 - val_accuracy: 0.8246\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0545 - accuracy: 0.9879 - val_loss: 0.4995 - val_accuracy: 0.8172\n",
            "Epoch 4/10\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9978\n",
            "Reached 99% accuracy so cancelling training!\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9978 - val_loss: 0.5383 - val_accuracy: 0.8265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4d7422a6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7YtuEbtl8j"
      },
      "source": [
        "### Extracting Embeddings from the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L20qim27BLZ",
        "outputId": "0185560f-cbe9-4ff2-8fe2-8874ca124f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embed_layer = model.layers[0]\n",
        "embed_weights = embed_layer.get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYOR3Aixtpst"
      },
      "source": [
        "### Exporting meta.tsv and vecs.tsv (embeddings) to visualize it in tensorflow projector in spherical form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObD811Xb-9uA"
      },
      "source": [
        "out_v = io.open(\"vecs.tsv\" , mode = 'w' , encoding='utf-8')\n",
        "out_m = io.open(\"meta.tsv\" , mode = 'w' , encoding='utf-8')\n",
        "\n",
        "for word_num in range(1,vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = embed_weights[word_num]\n",
        "  out_m.write(word + '\\n')\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + '\\n')\n",
        "out_m.close()\n",
        "out_v.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeleEsu-_xFD",
        "outputId": "ceee492a-f8d4-46e1-ef98-35e7960300c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_616527e2-6ce5-466c-9cce-419a061441f1\", \"vecs.tsv\", 3860555)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_06f56b13-1a04-4640-b7bb-f96522f02245\", \"meta.tsv\", 159021)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H__hp6UsNX4"
      },
      "source": [
        "### Testing the model on different Sentences ( if y_hat is above 0.5 review has been predicted positive and below 0.5 is a negative predicted review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryijmApru6fQ"
      },
      "source": [
        "### Creating function to convert sentences into padded sequences with the same hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-VDeDNWAP91"
      },
      "source": [
        "def get_pad_sequence(sentence_val):\n",
        "  sequence = tokenizer.texts_to_sequences([sentence_val])\n",
        "  padded_seq = pad_sequences(sequence , truncating = truncate , padding = pad , maxlen = max_length)\n",
        "  return padded_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X31zY3CtsNH7"
      },
      "source": [
        "Trying Positive Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31YSo2T8r881"
      },
      "source": [
        "sentence = \"I really think this is amazing. honest.\"\n",
        "padded_test_1 = get_pad_sequence(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR2xWWbzvr0l"
      },
      "source": [
        "0.99 means its a very positive review and the classifier is good in predicting posiitve reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpCR9rssrI_V",
        "outputId": "eea8d5fa-e0fd-4764-fb0b-0b274c383e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "model.predict(padded_test_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9824178]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYTaATujvG8Y"
      },
      "source": [
        "Trying Negative Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qxfLFYMrPJg"
      },
      "source": [
        "sentence = \"The movie was so boring , bad and not worth watching. I hated the movie and no one should have to sit through that\"\n",
        "padded_test_2 = get_pad_sequence(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNJvaE7XvT74",
        "outputId": "cbd5bc50-166a-485b-c05d-a2e2b2f6f315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "model.predict(padded_test_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00090715]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rsIl87vY_o"
      },
      "source": [
        "0.009 means its a very negative review and the model is correct"
      ]
    }
  ]
}